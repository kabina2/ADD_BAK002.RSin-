## Project Overview

This project investigates and compares the performance of three deep learning architectures—**Simple Neural Network (SimpleNN)**, **AlexNet**, and **TinyVGG**—on the **CIFAR-10 dataset**, which contains 60,000 32x32 color images across 10 distinct classes. The main objective is to analyze and evaluate each model based on **test accuracy, training efficiency, and model complexity**, highlighting the advantages of convolutional neural networks for image classification tasks.  

- **SimpleNN:** Serves as a baseline, representing a fully connected neural network to assess fundamental performance.  
- **AlexNet (CIFAR-10 adaptation):** A deeper convolutional network inspired by the original AlexNet, utilizing ReLU activations, dropout, and larger convolutional layers to enhance feature extraction and generalization.  
- **TinyVGG:** A lightweight CNN optimized for speed and computational efficiency, demonstrating that smaller architectures can still achieve competitive performance.  

This project provides a **comprehensive comparison** of these architectures, illustrating the trade-offs between model depth, accuracy, training time, and computational requirements, while emphasizing best practices in deep learning model design and evaluation.
